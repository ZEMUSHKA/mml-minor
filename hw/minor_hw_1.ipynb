{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:08:15.388798Z",
     "start_time": "2018-11-07T16:08:15.081241Z"
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "import matplotlib \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to use python 3 version of Kaggle!\n",
    "# remove python 2 version with `pip uninstall kaggle`\n",
    "! pip3 install kaggle --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T15:29:19.895974Z",
     "start_time": "2018-11-06T15:26:21.334564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train_simplified.zip to /home/zian\n",
      "100%|█████████████████████████████████████▉| 7.37G/7.37G [02:41<00:00, 85.0MB/s]\n",
      "100%|██████████████████████████████████████| 7.37G/7.37G [02:41<00:00, 48.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "# get <token> from https://www.kaggle.com/<user>/account, click \"Create New API Token\", open json file\n",
    "! KAGGLE_USERNAME=<user> KAGGLE_KEY=<token> kaggle competitions download -c quickdraw-doodle-recognition -f train_simplified.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:08:31.048432Z",
     "start_time": "2018-11-07T16:08:31.004128Z"
    }
   },
   "outputs": [],
   "source": [
    "# open zip file, will read everything from it\n",
    "zf = zipfile.ZipFile(\"train_simplified.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generators from disk (no need to store in RAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:09:00.917240Z",
     "start_time": "2018-11-07T16:09:00.906369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fence', 'yoga', 'horse', 'sandwich', 'cat']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = map(lambda x: x.replace(\".csv\", \"\"), zf.namelist())\n",
    "class_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:09:01.213496Z",
     "start_time": "2018-11-07T16:09:01.203670Z"
    }
   },
   "outputs": [],
   "source": [
    "# loop through file eternally\n",
    "def get_eternal_csv_generator(fn, debug=False):\n",
    "    while True:\n",
    "        with zf.open(fn) as f:\n",
    "            f.readline()  # skip header\n",
    "            for line in csv.reader(f, delimiter=',', quotechar='\"'):\n",
    "                yield line[1], line[5]\n",
    "            if debug:\n",
    "                print fn, \"is done, starting from the beginning...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:09:01.651230Z",
     "start_time": "2018-11-07T16:09:01.642356Z"
    }
   },
   "outputs": [],
   "source": [
    "def raw_batch_generator(batch_size, debug=False):\n",
    "    generators = np.array([get_eternal_csv_generator(fn, debug) for fn in zf.namelist()])\n",
    "    while True:\n",
    "        random_indices = np.random.randint(0, len(generators), size=batch_size)\n",
    "        yield [gen.next() for gen in generators[random_indices]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:09:04.267262Z",
     "start_time": "2018-11-07T16:09:04.251004Z"
    }
   },
   "outputs": [],
   "source": [
    "# copy-paste from https://www.kaggle.com/jpmiller/image-based-cnn\n",
    "\n",
    "import ast\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "IMG_SIZE = 64\n",
    "\n",
    "# faster conversion function\n",
    "def draw_it(strokes):\n",
    "    image = Image.new(\"P\", (256, 256), color=255)\n",
    "    image_draw = ImageDraw.Draw(image)\n",
    "    for stroke in ast.literal_eval(strokes):\n",
    "        for i in range(len(stroke[0])-1):\n",
    "            image_draw.line([stroke[0][i], \n",
    "                             stroke[1][i],\n",
    "                             stroke[0][i+1], \n",
    "                             stroke[1][i+1]],\n",
    "                            fill=0, width=5)\n",
    "    image = image.resize((IMG_SIZE, IMG_SIZE))\n",
    "    return np.array(image, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:09:07.131184Z",
     "start_time": "2018-11-07T16:09:07.120659Z"
    }
   },
   "outputs": [],
   "source": [
    "def images_and_labels_generator(batch_size):\n",
    "    for batch in raw_batch_generator(batch_size):\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for e in batch:\n",
    "            batch_images.append(draw_it(e[0]))\n",
    "            batch_labels.append(e[1])\n",
    "        batch_images = np.stack(batch_images, axis=0)\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:09:31.235828Z",
     "start_time": "2018-11-07T16:09:31.078072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = images_and_labels_generator(32).next()\n",
    "plt.imshow(b[0][10, :, :])\n",
    "plt.title(b[1][10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T22:00:38.205119Z",
     "start_time": "2018-11-06T22:00:38.199739Z"
    }
   },
   "source": [
    "# Train simple network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:09:43.935122Z",
     "start_time": "2018-11-07T16:09:43.339804Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:10:14.627454Z",
     "start_time": "2018-11-07T16:10:14.614258Z"
    }
   },
   "outputs": [],
   "source": [
    "# reset graph when you change architecture!\n",
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    K.clear_session()\n",
    "    # create new session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    s = tf.InteractiveSession(config=config)\n",
    "    K.set_session(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:10:20.833559Z",
     "start_time": "2018-11-07T16:10:20.820480Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('snowman', 134),\n",
       " ('eyeglasses', 254),\n",
       " ('ceiling fan', 18),\n",
       " ('camel', 90),\n",
       " ('stove', 119)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(class_labels)\n",
    "class_to_idx = {c: idx for idx, c in enumerate(class_labels)}\n",
    "class_to_idx.items()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:11:58.574802Z",
     "start_time": "2018-11-07T16:11:58.565415Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_iterator(batch_size):\n",
    "    for batch in images_and_labels_generator(batch_size):\n",
    "        images = batch[0].astype('float32')\n",
    "        ### YOUR CODE HERE: normalize images!\n",
    "        images = np.expand_dims(images, -1)\n",
    "        labels = keras.utils.to_categorical(map(class_to_idx.get, batch[1]), NUM_CLASSES)\n",
    "        yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:11:59.923327Z",
     "start_time": "2018-11-07T16:11:59.898171Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64, 1)\n",
      "(32, 340)\n"
     ]
    }
   ],
   "source": [
    "sample = train_iterator(32).next()\n",
    "print sample[0].shape\n",
    "print sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:12:13.491949Z",
     "start_time": "2018-11-07T16:12:13.485091Z"
    }
   },
   "outputs": [],
   "source": [
    "# import necessary building blocks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, GlobalAveragePooling2D, \\\n",
    "    BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:15:15.162847Z",
     "start_time": "2018-11-07T16:15:15.148961Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    \"\"\"\n",
    "    Define your model architecture here.\n",
    "    Returns `Sequential` model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    ### YOUR CODE HERE: replace with a better model! Batch normalization really helps!\n",
    "    \n",
    "    model.add(Conv2D(16, (3, 3), padding='same', activation='elu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "    model.add(Conv2D(16, (3, 3), padding='same', activation='elu'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(Dense(64, activation='elu'))\n",
    "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:15:16.796282Z",
     "start_time": "2018-11-07T16:15:16.726472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 16)        2320      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 340)               22100     \n",
      "=================================================================\n",
      "Total params: 25,668\n",
      "Trainable params: 25,668\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# describe model\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:21:07.829654Z",
     "start_time": "2018-11-07T16:21:07.822122Z"
    }
   },
   "outputs": [],
   "source": [
    "# custom metrics we need\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:16:27.284265Z",
     "start_time": "2018-11-07T16:16:27.184294Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "STEPS_PER_EPOCH = 100\n",
    "EPOCHS = 5\n",
    "\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()  # define our model\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.adam(clipnorm=5.),  # gradient clipping just in case\n",
    "    metrics=[categorical_accuracy, top_3_accuracy]  # report top 3 accuracy, correlates with MAP@3!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:20:03.725667Z",
     "start_time": "2018-11-07T16:20:03.715510Z"
    }
   },
   "outputs": [],
   "source": [
    "# for saving the model after every epoch\n",
    "from keras.models import save_model\n",
    "\n",
    "class ModelSaveCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, file_name):\n",
    "        super(ModelSaveCallback, self).__init__()\n",
    "        self.file_name = file_name\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        model_filename = self.file_name.format(epoch)\n",
    "        save_model(self.model, model_filename)\n",
    "        print(\"Model saved in {}\".format(model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:22:04.352396Z",
     "start_time": "2018-11-07T16:22:03.726954Z"
    }
   },
   "outputs": [],
   "source": [
    "last_finished_epoch = 0\n",
    "\n",
    "# you can continue from snapshot!!!\n",
    "# from keras.models import load_model\n",
    "# s = reset_tf_session()\n",
    "# last_finished_epoch = 2\n",
    "# model = load_model(\"model_{}\".format(last_finished_epoch), \n",
    "#                    custom_objects={\"top_3_accuracy\": top_3_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:22:12.823711Z",
     "start_time": "2018-11-07T16:22:08.154274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.8710 - categorical_accuracy: 0.0400 - top_3_accuracy: 0.0994\n",
      "Model saved in model_2\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.8869 - categorical_accuracy: 0.0428 - top_3_accuracy: 0.1122\n",
      "Model saved in model_3\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 4.8164 - categorical_accuracy: 0.0575 - top_3_accuracy: 0.1225\n",
      "Model saved in model_4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd40c0dacd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model with our eternal generator!\n",
    "model.fit_generator(\n",
    "    train_iterator(BATCH_SIZE), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[ModelSaveCallback(\"model_{}\")],\n",
    "    verbose=1,\n",
    "    initial_epoch=last_finished_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T12:18:38.307707Z",
     "start_time": "2018-11-07T12:18:34.929466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading test_simplified.csv to /home/zian\n",
      " 93%|███████████████████████████████████▍  | 55.0M/59.0M [00:01<00:00, 45.1MB/s]\n",
      "100%|██████████████████████████████████████| 59.0M/59.0M [00:01<00:00, 42.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "# download test set\n",
    "! KAGGLE_USERNAME=<user> KAGGLE_KEY=<token> kaggle competitions download -c quickdraw-doodle-recognition -f test_simplified.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:25:30.169624Z",
     "start_time": "2018-11-07T16:25:30.148875Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_csv_iterator(batch_size):\n",
    "    with open(\"test_simplified.csv\", \"r\") as f:\n",
    "        batch_keys = []\n",
    "        batch_images = []\n",
    "        f.readline()  # skip header\n",
    "        for line in csv.reader(f, delimiter=',', quotechar='\"'):\n",
    "            batch_keys.append(line[0])\n",
    "            batch_images.append(draw_it(line[2]))\n",
    "            if len(batch_images) == batch_size:\n",
    "                batch_images = np.stack(batch_images, axis=0)\n",
    "                batch_images = np.expand_dims(batch_images, -1)\n",
    "                batch_images = batch_images.astype('float32')\n",
    "                ### YOUR CODE HERE: normalize batch_images the same way as during training!\n",
    "                yield batch_keys, batch_images\n",
    "                batch_keys = []\n",
    "                batch_images = []\n",
    "        if batch_images:  # last batch\n",
    "            batch_images = np.stack(batch_images, axis=0)\n",
    "            batch_images = np.expand_dims(batch_images, -1)\n",
    "            batch_images = batch_images.astype('float32')\n",
    "            ### YOUR CODE HERE: normalize batch_images the same way as during training!\n",
    "            yield batch_keys, batch_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:25:32.406415Z",
     "start_time": "2018-11-07T16:25:32.203842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112200 test_simplified.csv\r\n"
     ]
    }
   ],
   "source": [
    "! wc -l test_simplified.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:26:30.259083Z",
     "start_time": "2018-11-07T16:25:32.579734Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82005d22d3064af0ad6a3c74260c5cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3507), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"submission.csv\", \"w\", buffering=1*1024*1024) as f:\n",
    "    f.write(\"key_id,word\\n\")\n",
    "    for batch_keys, batch_images in tqdm.tqdm_notebook(test_csv_iterator(BATCH_SIZE), total=np.ceil(112200./BATCH_SIZE)):\n",
    "        probas = model.predict_proba(batch_images, BATCH_SIZE)\n",
    "        top_3_classes = np.argsort(probas, axis=1)[:, [-1, -2, -3]]\n",
    "        labels = map(lambda x: \" \".join(\"_\".join(class_labels[idx].split()) for idx in x), top_3_classes)\n",
    "        for key, labels in zip(batch_keys, labels):\n",
    "            f.write(key + \",\" + labels + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:27:51.293010Z",
     "start_time": "2018-11-07T16:27:51.111607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112200 submission.csv\r\n"
     ]
    }
   ],
   "source": [
    "! wc -l submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T13:18:12.630549Z",
     "start_time": "2018-11-07T13:17:59.689315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4.44M/4.44M [00:10<00:00, 456kB/s]\n",
      "Successfully submitted to Quick, Draw! Doodle Recognition Challenge"
     ]
    }
   ],
   "source": [
    "# submit to kaggle\n",
    "! KAGGLE_USERNAME=<user> KAGGLE_KEY=<token> kaggle competitions submit quickdraw-doodle-recognition -f submission.csv -m \"My precious\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
